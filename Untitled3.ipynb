{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "from somajo import SoMaJo\n",
    "tokenizer = SoMaJo(\"de_CMC\", split_camel_case=True,split_sentences=True)\n",
    "def measurement(o):\n",
    "    s=[]\n",
    "    m=[]\n",
    "    sentences = tokenizer.tokenize_text(o)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for token in sentence:\n",
    "            if token.token_class=='measurement' or token.token_class=='number':\n",
    "                m.append(token.text)\n",
    "                \n",
    "            elif token.text!=['',',']:\n",
    "                s.append(token.text)\n",
    "    return s \n",
    "\n",
    "\n",
    "def abbre_extract(o):\n",
    "    abbre=[]\n",
    "    for a in o:\n",
    "        if re.search(r'\\.',a):\n",
    "            abbre.append(a)     \n",
    "    return abbre\n",
    "\n",
    "def shop(o):\n",
    "    shop=[]\n",
    "    abbr=[]\n",
    "    r=[]\n",
    "    abbre=[]\n",
    "    for a in o:\n",
    "        sentences = re.split(r\"([.,])\", a)\n",
    "        sentences.append(\"\")\n",
    "        sentences = [\"\".join(i) for i in zip(sentences[0::2], sentences[1::2])]\n",
    "        abbre = abbre+sentences\n",
    "    if len(abbre[0])<4:\n",
    "        if abbre[0].isupper() or re.search(r'\\d|\\-|\\&',abbre[0]):\n",
    "            shop.append(abbre[0])\n",
    "        elif re.search(r'\\.',abbre[0]):\n",
    "            abbr.append(abbre[0])  \n",
    "        else:r.append(abbre[0])\n",
    "    elif re.search(r'\\.',abbre[0]):\n",
    "        abbr.append(abbre[0])  \n",
    "    else:r.append(abbre[0])\n",
    "    for a in abbre[1:]:\n",
    "        if a=='0':\n",
    "            a=='O'\n",
    "        if re.search(r'\\.',a):\n",
    "            abbr.append(a) \n",
    "        else:r.append(a)\n",
    "    return shop\n",
    "def percen(o):\n",
    "    x=[]\n",
    "    for i,b in enumerate(o):\n",
    "        if re.search(r'\\%',b):\n",
    "            if len(b)<3 and re.search(r'\\d',o[i-1]):\n",
    "                x.append(''.join(''.join(re.findall(r'\\d|\\,',o[i-1]))+b))\n",
    "            elif re.search(r'\\%',b):\n",
    "                x.append(b)\n",
    "    return x\n",
    "def combine(o):\n",
    "    shop=[]\n",
    "    abbr=[]\n",
    "    r=[]\n",
    "    abbre=[]\n",
    "    for a in o:\n",
    "        sentences = re.split(r\"([.,])\", a)\n",
    "        sentences.append(\"\")\n",
    "        sentences = [\"\".join(i) for i in zip(sentences[0::2], sentences[1::2])]\n",
    "        abbre = abbre+sentences\n",
    "    if len(abbre[0])<4:\n",
    "        if abbre[0].isupper() or re.search(r'\\d|\\-|\\&',abbre[0]):\n",
    "            shop.append(abbre[0])  \n",
    "        else:r.append(abbre[0])  \n",
    "    else:r.append(abbre[0])\n",
    "    for a in abbre[1:]:\n",
    "        if a != '':\n",
    "            if a=='0':\n",
    "                r.append('o.')\n",
    "            if a=='01':\n",
    "                r.append('öl')\n",
    "            else:r.append(a)\n",
    "    s=[]\n",
    "    m=[]\n",
    "    for x in r:\n",
    "        if re.search(r'\\.',x):\n",
    "            s.append(x)\n",
    "        else:\n",
    "            tokens = tokenizer.tokenize_text([x])\n",
    "            for i, sentence in enumerate(tokens):\n",
    "                for token in sentence: \n",
    "                    if token.token_class=='measurement' or token.token_class=='number':\n",
    "                        m.append(token.text)\n",
    "                \n",
    "                    elif token.text!=['',',']:\n",
    "                        s.append(token.text)\n",
    "    u=[]\n",
    "    q=[]\n",
    "    for x in s:\n",
    "        u.append(''.join(x.split('-')))\n",
    "    for y in u:\n",
    "        if y not in ['',',','%','3.']:\n",
    "            q.append(y)\n",
    "    return q\n",
    "\n",
    "def singlecorrection(o):\n",
    "    sym_spell = SymSpell(max_dictionary_edit_distance=5)\n",
    "    dictionary_path = 'new.txt'\n",
    "    #dictionary_path = 'word_combine_lower.txt'\n",
    "    #dictionary_path = 'word_supervised.txt'\n",
    "    #dictionary_path = 'word_withshop.txt'\n",
    "    sym_spell.load_dictionary(dictionary_path, 0, 1, separator=\"$\")\n",
    "    w=[]\n",
    "    for a in o:\n",
    "        suggestions = sym_spell.lookup(a.lower().replace('10','lo').replace('1','i'), Verbosity.CLOSEST, max_edit_distance=5)\n",
    "        if suggestions:\n",
    "            w.append(suggestions[0].term)\n",
    "        else: w.append(a)\n",
    "    return w\n",
    "\n",
    "def segcorrection(o):\n",
    "    sym_spell = SymSpell(max_dictionary_edit_distance=5)\n",
    "    dictionary_path = 'new.txt'\n",
    "    #dictionary_path = 'word_combine_lower.txt'\n",
    "    #dictionary_path = 'word_supervised.txt'\n",
    "    #dictionary_path = 'word_withshop.txt'\n",
    "    sym_spell.load_dictionary(dictionary_path, 0, 1, separator=\"$\")\n",
    "    w=[]\n",
    "    a=''.join(o).replace('10','lo').replace('1','i')\n",
    "    if a:\n",
    "        result=sym_spell.word_segmentation(a.lower(),max_edit_distance=5)\n",
    "        w.append(result.corrected_string)\n",
    "    else: w.append(a)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "stop_word=['UKE','uke','vak.','VKE','QS','Stück','kg','-QS','ST','x','IL','Kg','US']\n",
    "df = pd.read_csv('../新/OCR_compare001.csv',sep=';')\n",
    "df =df.drop(columns=['Unnamed: 0','Unnamed: 3'])\n",
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "df['edit']=df['OCR'].apply(lambda x: [word for word in re.split(' |/',x)if word not in stop_word])\n",
    "df['percentage']=df['edit'].apply(percen)\n",
    "df['shop']=df['edit'].apply(shop)\n",
    "df['combine']=df['edit'].apply(combine)\n",
    "df['singlecorrection']=df['combine'].apply(singlecorrection)\n",
    "df['segcorrection']=df['combine'].apply(segcorrection)\n",
    "#df.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('1111.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OCR</th>\n",
       "      <th>ACTUAL</th>\n",
       "      <th>edit</th>\n",
       "      <th>percentage</th>\n",
       "      <th>shop</th>\n",
       "      <th>combine</th>\n",
       "      <th>singlecorrection</th>\n",
       "      <th>segcorrection</th>\n",
       "      <th>same_result</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orangen 10se</td>\n",
       "      <td>Orangen lose</td>\n",
       "      <td>[Orangen, 10se]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Orangen, 10se]</td>\n",
       "      <td>[orangen, lose]</td>\n",
       "      <td>[orangen lose]</td>\n",
       "      <td>[orangen, lose]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apfel Morgana</td>\n",
       "      <td>Äpfel Morgana</td>\n",
       "      <td>[Apfel, Morgana]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Apfel, Morgana]</td>\n",
       "      <td>[apfel, morgana]</td>\n",
       "      <td>[apfel morgana]</td>\n",
       "      <td>[apfel, morgana]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kiui gold Stück</td>\n",
       "      <td>Kiwi gold Stück</td>\n",
       "      <td>[Kiui, gold]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Kiui, gold]</td>\n",
       "      <td>[kiwi, gold]</td>\n",
       "      <td>[kiwi gold]</td>\n",
       "      <td>[kiwi, gold]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kiui grün Stück</td>\n",
       "      <td>Kiwi grün Stück</td>\n",
       "      <td>[Kiui, grün]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Kiui, grün]</td>\n",
       "      <td>[kiwi, grün]</td>\n",
       "      <td>[kiwi grün]</td>\n",
       "      <td>[kiwi, grün]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teonen Stück</td>\n",
       "      <td>Zitronen Stück</td>\n",
       "      <td>[teonen]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[teonen]</td>\n",
       "      <td>[tropen]</td>\n",
       "      <td>[tropen]</td>\n",
       "      <td>[tropen]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>Mezzo M</td>\n",
       "      <td>Mezzo Mix</td>\n",
       "      <td>[Mezzo, M]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Mezzo, M]</td>\n",
       "      <td>[mezzo, im]</td>\n",
       "      <td>[mezzo]</td>\n",
       "      <td>None</td>\n",
       "      <td>[mezzo, im]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>Galiamelone</td>\n",
       "      <td>Galiamelone</td>\n",
       "      <td>[Galiamelone]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Galiamelone]</td>\n",
       "      <td>[galiamelone]</td>\n",
       "      <td>[galiamelone]</td>\n",
       "      <td>[galiamelone]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>Hasserme longe kern</td>\n",
       "      <td>Wassermelonen kern</td>\n",
       "      <td>[Hasserme, longe, kern]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Hasserme, longe, kern]</td>\n",
       "      <td>[wasser, lange, kern]</td>\n",
       "      <td>[wassermelone kern]</td>\n",
       "      <td>None</td>\n",
       "      <td>[wassermelone, kern]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>Kaki stück</td>\n",
       "      <td>Kaki stück</td>\n",
       "      <td>[Kaki, stück]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Kaki, stück]</td>\n",
       "      <td>[kaki, stück]</td>\n",
       "      <td>[kaki stück]</td>\n",
       "      <td>[kaki, stück]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>Müs i-Riegel</td>\n",
       "      <td>Müsli-Riegel</td>\n",
       "      <td>[Müs, i-Riegel]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Müs, iRiegel]</td>\n",
       "      <td>[mus, riegel]</td>\n",
       "      <td>[müsliriegel]</td>\n",
       "      <td>None</td>\n",
       "      <td>[müsliriegel]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1021 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      OCR              ACTUAL                     edit  \\\n",
       "0            Orangen 10se        Orangen lose          [Orangen, 10se]   \n",
       "1           Apfel Morgana       Äpfel Morgana         [Apfel, Morgana]   \n",
       "2         Kiui gold Stück     Kiwi gold Stück             [Kiui, gold]   \n",
       "3         Kiui grün Stück     Kiwi grün Stück             [Kiui, grün]   \n",
       "4            teonen Stück      Zitronen Stück                 [teonen]   \n",
       "...                   ...                 ...                      ...   \n",
       "1025              Mezzo M           Mezzo Mix               [Mezzo, M]   \n",
       "1026          Galiamelone         Galiamelone            [Galiamelone]   \n",
       "1027  Hasserme longe kern  Wassermelonen kern  [Hasserme, longe, kern]   \n",
       "1028           Kaki stück          Kaki stück            [Kaki, stück]   \n",
       "1029         Müs i-Riegel        Müsli-Riegel          [Müs, i-Riegel]   \n",
       "\n",
       "     percentage shop                  combine       singlecorrection  \\\n",
       "0            []   []          [Orangen, 10se]        [orangen, lose]   \n",
       "1            []   []         [Apfel, Morgana]       [apfel, morgana]   \n",
       "2            []   []             [Kiui, gold]           [kiwi, gold]   \n",
       "3            []   []             [Kiui, grün]           [kiwi, grün]   \n",
       "4            []   []                 [teonen]               [tropen]   \n",
       "...         ...  ...                      ...                    ...   \n",
       "1025         []   []               [Mezzo, M]            [mezzo, im]   \n",
       "1026         []   []            [Galiamelone]          [galiamelone]   \n",
       "1027         []   []  [Hasserme, longe, kern]  [wasser, lange, kern]   \n",
       "1028         []   []            [Kaki, stück]          [kaki, stück]   \n",
       "1029         []   []           [Müs, iRiegel]          [mus, riegel]   \n",
       "\n",
       "            segcorrection       same_result                 final  \n",
       "0          [orangen lose]   [orangen, lose]                     1  \n",
       "1         [apfel morgana]  [apfel, morgana]                     1  \n",
       "2             [kiwi gold]      [kiwi, gold]                     1  \n",
       "3             [kiwi grün]      [kiwi, grün]                     1  \n",
       "4                [tropen]          [tropen]                     1  \n",
       "...                   ...               ...                   ...  \n",
       "1025              [mezzo]              None           [mezzo, im]  \n",
       "1026        [galiamelone]     [galiamelone]                     1  \n",
       "1027  [wassermelone kern]              None  [wassermelone, kern]  \n",
       "1028         [kaki stück]     [kaki, stück]                     1  \n",
       "1029        [müsliriegel]              None         [müsliriegel]  \n",
       "\n",
       "[1021 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import Levenshtein \n",
    "import chars2vec\n",
    "import sklearn.decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "c2v_model = chars2vec.load_model('eng_150')\n",
    "def score(arg1, arg2, arg3):\n",
    "    texta =''.join(arg1).lower()\n",
    "    textb = ''.join(arg2)\n",
    "    textc = ''.join(''.join(arg3).split(\" \"))\n",
    "    if textb!=textc:\n",
    "        words = [texta, textb, textc]\n",
    "    else:\n",
    "        return 1\n",
    "    #if texta!='':\n",
    "        #word_embeddings = c2v_model.vectorize_words(words)\n",
    "        #score1=\"%10.4f\" % np.linalg.norm(word_embeddings[0] - word_embeddings[1])\n",
    "        #score2=\"%10.4f\" % np.linalg.norm(word_embeddings[0] - word_embeddings[2])\n",
    "    score1=Levenshtein.distance(texta,textb)\n",
    "    score2=Levenshtein.distance(texta,textc)\n",
    "    if score2 < score1:\n",
    "        return ''.join(arg3).split(\" \")\n",
    "    else:\n",
    "        return arg2\n",
    "    \n",
    "def func(arg1, arg2):\n",
    "    if ''.join(arg1)==''.join(''.join(arg2).split(\" \")):\n",
    "        return arg1\n",
    "df['same_result']= df.apply(lambda row:func(row['singlecorrection'],row['segcorrection']), axis = 1)\n",
    "df['final']=df.apply(lambda row:score(row['combine'],row['singlecorrection'],row['segcorrection']), axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import collections\n",
    "from operator import itemgetter\n",
    "\n",
    "WORDFILE = 'new_COR1.txt'\n",
    "class Autocorrect(object):\n",
    "    def __init__(self, ngram_size=3, len_variance=3):\n",
    "        self.ngram_size = ngram_size\n",
    "        self.len_variance = len_variance\n",
    "        self.words = set([w.lower().strip() for w in open(WORDFILE).read().splitlines()])\n",
    "        self.ngram_words = collections.defaultdict(set)\n",
    "        for word in self.words:\n",
    "            for ngram in self.ngrams(word):\n",
    "                self.ngram_words[ngram].add(word)\n",
    "    def lookup(self, word):\n",
    "        return word.lower() in self.words\n",
    "    def ngrams(self, word):\n",
    "        all_ngrams = set()\n",
    "        for i in range(0, len(word) - self.ngram_size + 1):\n",
    "            all_ngrams.add(word[i:i + self.ngram_size])\n",
    "        return all_ngrams\n",
    "    def change(o):\n",
    "        a=''\n",
    "        for x in o:\n",
    "            a=a+\" \"+x\n",
    "        return ''.join(a)\n",
    "\n",
    "    def suggested_words(self, target_word, results=5):\n",
    "        word_ranking = collections.defaultdict(int)\n",
    "        possible_words = set()\n",
    "        if target_word != 1:\n",
    "            target_word=change(target_word)[1:]\n",
    "        else: return 2\n",
    "        for ngram in self.ngrams(target_word):\n",
    "            words = self.ngram_words[ngram]\n",
    "            for word in words:\n",
    "                if len(word) >= len(target_word) - self.len_variance and \\\n",
    "                   len(word) <= len(target_word) + self.len_variance:\n",
    "                    word_ranking[word] += 1\n",
    "        ranked_word_pairs = sorted(word_ranking.items(), key=itemgetter(1), reverse=True)\n",
    "        if ranked_word_pairs != []:\n",
    "            if self.lookup(target_word):\n",
    "                    return target_word\n",
    "            else:\n",
    "                return ranked_word_pairs[0][0]\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OCR</th>\n",
       "      <th>ACTUAL</th>\n",
       "      <th>edit</th>\n",
       "      <th>percentage</th>\n",
       "      <th>shop</th>\n",
       "      <th>combine</th>\n",
       "      <th>singlecorrection</th>\n",
       "      <th>segcorrection</th>\n",
       "      <th>same_result</th>\n",
       "      <th>final</th>\n",
       "      <th>suggest</th>\n",
       "      <th>result</th>\n",
       "      <th>corr_shop</th>\n",
       "      <th>corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orangen 10se</td>\n",
       "      <td>Orangen lose</td>\n",
       "      <td>[Orangen, 10se]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[Orangen, 10se]</td>\n",
       "      <td>[orangen, lose]</td>\n",
       "      <td>[orangen lose]</td>\n",
       "      <td>[orangen, lose]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>orangen lose</td>\n",
       "      <td></td>\n",
       "      <td>orangen lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apfel Morgana</td>\n",
       "      <td>Äpfel Morgana</td>\n",
       "      <td>[Apfel, Morgana]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[Apfel, Morgana]</td>\n",
       "      <td>[apfel, morgana]</td>\n",
       "      <td>[apfel morgana]</td>\n",
       "      <td>[apfel, morgana]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>apfel morgana</td>\n",
       "      <td></td>\n",
       "      <td>apfel morgana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kiui gold Stück</td>\n",
       "      <td>Kiwi gold Stück</td>\n",
       "      <td>[Kiui, gold]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[Kiui, gold]</td>\n",
       "      <td>[kiwi, gold]</td>\n",
       "      <td>[kiwi gold]</td>\n",
       "      <td>[kiwi, gold]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>kiwi gold</td>\n",
       "      <td></td>\n",
       "      <td>kiwi gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kiui grün Stück</td>\n",
       "      <td>Kiwi grün Stück</td>\n",
       "      <td>[Kiui, grün]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[Kiui, grün]</td>\n",
       "      <td>[kiwi, grün]</td>\n",
       "      <td>[kiwi grün]</td>\n",
       "      <td>[kiwi, grün]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>kiwi grün</td>\n",
       "      <td></td>\n",
       "      <td>kiwi grün</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teonen Stück</td>\n",
       "      <td>Zitronen Stück</td>\n",
       "      <td>[teonen]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[teonen]</td>\n",
       "      <td>[tropen]</td>\n",
       "      <td>[tropen]</td>\n",
       "      <td>[tropen]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>tropen</td>\n",
       "      <td></td>\n",
       "      <td>tropen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>Mezzo M</td>\n",
       "      <td>Mezzo Mix</td>\n",
       "      <td>[Mezzo, M]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[Mezzo, M]</td>\n",
       "      <td>[mezzo, im]</td>\n",
       "      <td>[mezzo]</td>\n",
       "      <td>None</td>\n",
       "      <td>[mezzo, im]</td>\n",
       "      <td>mezzo mix</td>\n",
       "      <td>mezzo mix</td>\n",
       "      <td></td>\n",
       "      <td>mezzo mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>Galiamelone</td>\n",
       "      <td>Galiamelone</td>\n",
       "      <td>[Galiamelone]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[Galiamelone]</td>\n",
       "      <td>[galiamelone]</td>\n",
       "      <td>[galiamelone]</td>\n",
       "      <td>[galiamelone]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>galiamelone</td>\n",
       "      <td></td>\n",
       "      <td>galiamelone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>Hasserme longe kern</td>\n",
       "      <td>Wassermelonen kern</td>\n",
       "      <td>[Hasserme, longe, kern]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[Hasserme, longe, kern]</td>\n",
       "      <td>[wasser, lange, kern]</td>\n",
       "      <td>[wassermelone kern]</td>\n",
       "      <td>None</td>\n",
       "      <td>[wassermelone, kern]</td>\n",
       "      <td>wassermelonen kern</td>\n",
       "      <td>wassermelonen kern</td>\n",
       "      <td></td>\n",
       "      <td>wassermelonen kern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>Kaki stück</td>\n",
       "      <td>Kaki stück</td>\n",
       "      <td>[Kaki, stück]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[Kaki, stück]</td>\n",
       "      <td>[kaki, stück]</td>\n",
       "      <td>[kaki stück]</td>\n",
       "      <td>[kaki, stück]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>kaki stück</td>\n",
       "      <td></td>\n",
       "      <td>kaki stück</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>Müs i-Riegel</td>\n",
       "      <td>Müsli-Riegel</td>\n",
       "      <td>[Müs, i-Riegel]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[Müs, iRiegel]</td>\n",
       "      <td>[mus, riegel]</td>\n",
       "      <td>[müsliriegel]</td>\n",
       "      <td>None</td>\n",
       "      <td>[müsliriegel]</td>\n",
       "      <td>müsliriegel</td>\n",
       "      <td>müsliriegel</td>\n",
       "      <td></td>\n",
       "      <td>müsliriegel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1021 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      OCR              ACTUAL                     edit  \\\n",
       "0            Orangen 10se        Orangen lose          [Orangen, 10se]   \n",
       "1           Apfel Morgana       Äpfel Morgana         [Apfel, Morgana]   \n",
       "2         Kiui gold Stück     Kiwi gold Stück             [Kiui, gold]   \n",
       "3         Kiui grün Stück     Kiwi grün Stück             [Kiui, grün]   \n",
       "4            teonen Stück      Zitronen Stück                 [teonen]   \n",
       "...                   ...                 ...                      ...   \n",
       "1025              Mezzo M           Mezzo Mix               [Mezzo, M]   \n",
       "1026          Galiamelone         Galiamelone            [Galiamelone]   \n",
       "1027  Hasserme longe kern  Wassermelonen kern  [Hasserme, longe, kern]   \n",
       "1028           Kaki stück          Kaki stück            [Kaki, stück]   \n",
       "1029         Müs i-Riegel        Müsli-Riegel          [Müs, i-Riegel]   \n",
       "\n",
       "     percentage shop                  combine       singlecorrection  \\\n",
       "0                 []          [Orangen, 10se]        [orangen, lose]   \n",
       "1                 []         [Apfel, Morgana]       [apfel, morgana]   \n",
       "2                 []             [Kiui, gold]           [kiwi, gold]   \n",
       "3                 []             [Kiui, grün]           [kiwi, grün]   \n",
       "4                 []                 [teonen]               [tropen]   \n",
       "...         ...  ...                      ...                    ...   \n",
       "1025              []               [Mezzo, M]            [mezzo, im]   \n",
       "1026              []            [Galiamelone]          [galiamelone]   \n",
       "1027              []  [Hasserme, longe, kern]  [wasser, lange, kern]   \n",
       "1028              []            [Kaki, stück]          [kaki, stück]   \n",
       "1029              []           [Müs, iRiegel]          [mus, riegel]   \n",
       "\n",
       "            segcorrection       same_result                 final  \\\n",
       "0          [orangen lose]   [orangen, lose]                     1   \n",
       "1         [apfel morgana]  [apfel, morgana]                     1   \n",
       "2             [kiwi gold]      [kiwi, gold]                     1   \n",
       "3             [kiwi grün]      [kiwi, grün]                     1   \n",
       "4                [tropen]          [tropen]                     1   \n",
       "...                   ...               ...                   ...   \n",
       "1025              [mezzo]              None           [mezzo, im]   \n",
       "1026        [galiamelone]     [galiamelone]                     1   \n",
       "1027  [wassermelone kern]              None  [wassermelone, kern]   \n",
       "1028         [kaki stück]     [kaki, stück]                     1   \n",
       "1029        [müsliriegel]              None         [müsliriegel]   \n",
       "\n",
       "                 suggest              result corr_shop             corrected  \n",
       "0                      2        orangen lose                   orangen lose   \n",
       "1                      2       apfel morgana                  apfel morgana   \n",
       "2                      2           kiwi gold                      kiwi gold   \n",
       "3                      2           kiwi grün                      kiwi grün   \n",
       "4                      2              tropen                         tropen   \n",
       "...                  ...                 ...       ...                   ...  \n",
       "1025           mezzo mix           mezzo mix                      mezzo mix   \n",
       "1026                   2         galiamelone                    galiamelone   \n",
       "1027  wassermelonen kern  wassermelonen kern             wassermelonen kern   \n",
       "1028                   2          kaki stück                     kaki stück   \n",
       "1029         müsliriegel         müsliriegel                    müsliriegel   \n",
       "\n",
       "[1021 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def change(o):\n",
    "    a=''\n",
    "    for x in o:\n",
    "        a=a+\" \"+x\n",
    "    return ''.join(a)[1:]\n",
    "def conn(arg1,arg2,arg3):\n",
    "    if arg1 == None and arg2==1:\n",
    "        return ''\n",
    "    elif arg1 == None and arg2!=1:\n",
    "        return arg3\n",
    "    else:return change(arg1) \n",
    "    \n",
    "def shopcorrection(o):\n",
    "    sym_spell1 = SymSpell(max_dictionary_edit_distance=5)\n",
    "    dictionary_path1 = 'shopcorr.txt'\n",
    "    #dictionary_path = 'word_combine_lower.txt'\n",
    "    #dictionary_path = 'word_supervised.txt'\n",
    "    #dictionary_path = 'word_withshop.txt'\n",
    "    sym_spell1.load_dictionary(dictionary_path1, 0, 1, separator=\"$\")\n",
    "    w=[]\n",
    "    for a in o:\n",
    "        suggestions = sym_spell1.lookup(a, Verbosity.CLOSEST, max_edit_distance=5)\n",
    "        if suggestions:\n",
    "            w.append(suggestions[0].term)\n",
    "        #else: w.append(a)\n",
    "    return w\n",
    "def appen(arg1,arg2,arg3):\n",
    "    if arg1 !='':\n",
    "        \n",
    "        s=''.join(change(arg1))+arg2\n",
    "    else: s=arg2\n",
    "    if arg3 !=[]:\n",
    "        s=s+arg3\n",
    "    return s\n",
    "        \n",
    "    \n",
    "spellchecker=Autocorrect()\n",
    "df['suggest']=df['final'].apply(spellchecker.suggested_words)\n",
    "df['result']=df.apply(lambda row: conn(row['same_result'],row['final'],row['suggest']), axis = 1)\n",
    "df['corr_shop']=df.apply(lambda row: shopcorrection(row['shop']), axis = 1)\n",
    "df['corr_shop']=df['corr_shop'].apply(change)\n",
    "df['percentage']=df['percentage'].apply(change)\n",
    "df['corrected']=df['corr_shop'].map(str)+\" \"+df['result']+\" \"+df['percentage'].map(str)\n",
    "#df['corrected']=df['corrected'].apply(lambda x: x.replace('[','').replace(']','').replace('',''))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orangen lose\n"
     ]
    }
   ],
   "source": [
    "a=['orangen', 'lose']\n",
    "def change(o):\n",
    "    a=''\n",
    "    for x in o:\n",
    "        a=a+\" \"+x\n",
    "    return ''.join(a)\n",
    "change(a)\n",
    "print(''.join(change(a)[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('try_jacob_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
